{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "## Deadlines ([AoE](https://en.wikipedia.org/wiki/Anywhere_on_Earth))\n",
    "\n",
    "* Sunday, December 4th for Task3.1 and Task3.2\n",
    "* Sunday, December 11th for Task3.3 and Task3.4\n",
    "* Sunday, December 18th for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import *\n",
    "from operator import *\n",
    "import math\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(strategyA: Callable, strategyB: Callable, num_matches = 1, nim_size = 3, k = None) -> float:\n",
    "    players = (strategyA, strategyB)\n",
    "    won = 0\n",
    "\n",
    "    for _ in range(num_matches):\n",
    "        nim = Nim(nim_size, k)\n",
    "        player = 1\n",
    "        while nim:\n",
    "            ply = players[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 1:\n",
    "            won += 1\n",
    "    return won / num_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_strategy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random non empty row and remove a random number of objects smaller than min(k, row_objects)\n",
    "\n",
    "def random_strategy(state: Nim):\n",
    "    r = random.choice([idx for idx, r in enumerate(state.rows) if r > 0])\n",
    "    num_objects = random.randint(1, min(state.rows[r], state.k) if state.k != None else state.rows[r])\n",
    "\n",
    "    return (r, num_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: Fixed-Rule Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among all possible moves, simply do this:\n",
    "# - if there is a winning move, choose it\n",
    "# - if there is not a winning move but the move puts the opponent in a winning situation, discard it\n",
    "# - otherwise choose the first move possible, even if not optimal (obliged to do a move)\n",
    "\n",
    "def fixed_strategy(state: Nim):\n",
    "    possible_moves = ((r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k)\n",
    "    move = None\n",
    "    firstMove = None\n",
    "\n",
    "    for m in possible_moves:\n",
    "        if firstMove == None:\n",
    "            firstMove = Nimply(m[0], m[1])\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        if not tmp:\n",
    "            return Nimply(m[0], m[1])\n",
    "        else:\n",
    "            active_rows = len([r for r in state.rows if r > 0])\n",
    "            eliminable_rows = len([r for r in state.rows if r > 0 and (state.k == None or r < state.k)])\n",
    "            if active_rows == eliminable_rows and eliminable_rows == 1:\n",
    "                continue\n",
    "            elif move == None:\n",
    "                move = Nimply(m[0], m[1])\n",
    "\n",
    "    return move if move != None else firstMove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Evolved Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import *\n",
    "from statistics import *\n",
    "\n",
    "GENOME_LENGTH = 11 # NB: GENOME_LENGTH must be of the form 4*n + 3 with n > 0, if n > 1 it may converge to the xor solution\n",
    "GAME_PARS = list((a, b) for a, b in product(range(2, 10, 3), list(range(1, 10, 3)) + [None]) if b == None or b < a)\n",
    "GAMES = len(GAME_PARS)\n",
    "\n",
    "def decode_genome(genome):\n",
    "    assert (GENOME_LENGTH - 3) % 4 == 0 and GENOME_LENGTH > 0, 'GENOME_LENGTH must be of the form 4*n + 3 with n > 0'\n",
    "    out = \"\"\n",
    "\n",
    "    for op_start in range(0, GENOME_LENGTH, 4):\n",
    "        tmpA = 'a' if genome[op_start] < 0.5 else '!a'\n",
    "        tmpB = 'b' if genome[op_start + 2] < 0.5 else '!b'\n",
    "        internal_op = '&' if genome[op_start + 1] < 0.5 else '|'\n",
    "        op = ('&' if genome[op_start + 3] < 0.5 else '|') if op_start + 3 < GENOME_LENGTH else ''\n",
    "        out += f'({tmpA} {internal_op} {tmpB}) {op} '\n",
    "\n",
    "    return out[:-2]\n",
    "\n",
    "\n",
    "def evolvable_strategy(genome):\n",
    "    assert (GENOME_LENGTH - 3) % 4 == 0 and GENOME_LENGTH > 0, 'GENOME_LENGTH must be of the form 4*n + 3 with n > 0'\n",
    "\n",
    "    def genetic_op(a, b):\n",
    "        result = 0\n",
    "        op = lambda _, b: b\n",
    "\n",
    "        for op_start in range(0, GENOME_LENGTH, 4):\n",
    "            tmpA = a if genome[op_start] < 0.5 else ~a\n",
    "            tmpB = b if genome[op_start + 2] < 0.5 else ~b\n",
    "            internal_op = and_ if genome[op_start + 1] < 0.5 else or_\n",
    "            result = op(result, internal_op(tmpA, tmpB))\n",
    "            op = (and_ if genome[op_start + 3] < 0.5 else or_) if op_start + 3 < GENOME_LENGTH else None\n",
    "\n",
    "        return result\n",
    "\n",
    "    def strategy(state: Nim):\n",
    "            possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k]\n",
    "            best = None\n",
    "\n",
    "            for m in possible_moves:\n",
    "                tmp = deepcopy(state)\n",
    "                tmp.nimming(m)\n",
    "                \n",
    "                val = reduce(genetic_op, tmp.rows)\n",
    "\n",
    "                if best == None or best[1] > val:\n",
    "                    best = (m, val)\n",
    "                             \n",
    "            return best[0]\n",
    "    \n",
    "    return strategy\n",
    "\n",
    "def mutation(genome):\n",
    "    point = random.randint(0, len(genome) - 1)\n",
    "    return genome[:point] + [1 - genome[point]] + genome[point + 1:]\n",
    "\n",
    "def crossover(genomeA, genomeB):\n",
    "    p = random.random()\n",
    "    return [x if p < 0.5 else y for x, y in zip(genomeA, genomeB)]\n",
    "\n",
    "def tournament(population, tournament_size):\n",
    "    return max(random.choices(population, k=tournament_size), key=lambda i: i.fitness)\n",
    "\n",
    "def fitness(genome):\n",
    "    win_optimal = 0.0\n",
    "    win_random = 0.0\n",
    "\n",
    "    for nim_size, k in GAME_PARS:\n",
    "        home = evaluate(evolvable_strategy(genome), random_strategy, nim_size=nim_size, k=k) \n",
    "        away = 1 - evaluate(random_strategy, evolvable_strategy(genome), nim_size=nim_size, k=k)\n",
    "        win_random += home + away\n",
    "        home = evaluate(evolvable_strategy(genome), optimal_strategy, nim_size=nim_size, k=k) \n",
    "        away = 1 - evaluate(optimal_strategy, evolvable_strategy(genome), nim_size=nim_size, k=k)\n",
    "        win_optimal += home + away\n",
    "\n",
    "    return (win_optimal/(2*GAMES), win_random/(2*GAMES))\n",
    "        \n",
    "def genetic_algorithm():\n",
    "    Individual = namedtuple('Individual', ('genome', 'fitness'))\n",
    "\n",
    "    NUM_GENS = 100    \n",
    "    POPULATION_SIZE = 10\n",
    "    OFFSPRING_SIZE = 20\n",
    "    TOURNAMENT_SIZE = 2\n",
    "    USELESS_GENS = 0\n",
    "    STEADY_STATE_LIMIT = 5\n",
    "\n",
    "    population = [Individual(i, fitness(i)) for i in ([round(random.random(), 2) for _ in range(GENOME_LENGTH)] for _ in range(POPULATION_SIZE))]\n",
    "    best = None\n",
    "    \n",
    "    for g in range(NUM_GENS):\n",
    "        offspring = list()\n",
    "        for i in range(OFFSPRING_SIZE):\n",
    "            if random.random() < 0.3:\n",
    "                p = tournament(population, tournament_size=TOURNAMENT_SIZE)\n",
    "                o = mutation(p.genome)\n",
    "            else:\n",
    "                p1 = tournament(population, tournament_size=TOURNAMENT_SIZE)\n",
    "                p2 = tournament(population, tournament_size=TOURNAMENT_SIZE)\n",
    "                o = crossover(p1.genome, p2.genome)\n",
    "            f = fitness(o)\n",
    "            offspring.append(Individual(o, f))\n",
    "        population += offspring\n",
    "        population = sorted(population, key=lambda i: i.fitness, reverse=True)[:POPULATION_SIZE]\n",
    "        newBest = max(population, key=lambda i: i.fitness)\n",
    "\n",
    "        if best != None and newBest <= best:\n",
    "            logging.info(f'Gen {g+1} skipped because useless')\n",
    "            USELESS_GENS += 1\n",
    "        else:\n",
    "            logging.info(f'Gen {g+1}, found new best individual: {decode_genome(newBest.genome)} with fitness = {newBest.fitness}')\n",
    "            best = newBest\n",
    "            USELESS_GENS = 0\n",
    "        \n",
    "        if USELESS_GENS == STEADY_STATE_LIMIT:\n",
    "            logging.info(f'Gen {g+1}, no improvements after {USELESS_GENS} gens, terminating...')\n",
    "            break\n",
    "\n",
    "    logging.info(f'Best individual: {decode_genome(best.genome)} with genome {best.genome} fitness = {best.fitness}')\n",
    "\n",
    "    return evolvable_strategy(best.genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen 1, found new best individual: (a & !b) & (!a | b) | (a | b) with fitness = (0.2777777777777778, 0.8333333333333334)\n",
      "Gen 2 skipped because useless\n",
      "Gen 3 skipped because useless\n",
      "Gen 4 skipped because useless\n",
      "Gen 5, found new best individual: (a & !b) & (!a | b) | (a | b) with fitness = (0.3333333333333333, 0.8333333333333334)\n",
      "Gen 6 skipped because useless\n",
      "Gen 7 skipped because useless\n",
      "Gen 8 skipped because useless\n",
      "Gen 9 skipped because useless\n",
      "Gen 10 skipped because useless\n",
      "Gen 10, no improvements after 5 gens, terminating...\n",
      "Best individual: (a & !b) & (!a | b) | (a | b) with genome [0.49, 0.04, 0.6, 0.29, 0.7, 0.62, 0.34, 0.92, 0.03, 0.57, 0.34] fitness = (0.3333333333333333, 0.8333333333333334)\n"
     ]
    }
   ],
   "source": [
    "evolved_strategy = genetic_algorithm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3: Min-Max Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_strategy_no_pruning(state: Nim):\n",
    "    def minmax(state: Nim, current_player, level = 0):\n",
    "        possible_moves = ((r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k)\n",
    "        current_func = min if current_player == 1 else max\n",
    "        tabs = '\\t' * level\n",
    "        if not state:\n",
    "            #logging.debug(f'{tabs} Level: {level}, Winner: {1 if level % 2 == 1 else -1}')\n",
    "            return None, current_player\n",
    "\n",
    "        evaluations = list()\n",
    "        for m in possible_moves:\n",
    "            tmp = deepcopy(state)\n",
    "            tmp.nimming(m)\n",
    "            #logging.debug(f\"{tabs} Level: {level}, Move: {m}, State: {tmp}, Player: {-current_player}\")\n",
    "            _, val = minmax(tmp, -current_player, level + 1)\n",
    "            evaluations.append((m, val))\n",
    "            \n",
    "        #logging.debug(f\"{tabs} Level: {level}, Evals: {evaluations}, Player: {-current_player}\")\n",
    "        return current_func(evaluations, key=lambda k: k[1])\n",
    "      \n",
    "\n",
    "    move, _ = minmax(state, 1)\n",
    "\n",
    "    return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_reached = 0\n",
    "def minmax(bound=math.inf):\n",
    "    def minmax(state: Nim, alpha, beta, current_player, depth=0):\n",
    "        global max_depth_reached\n",
    "        max_depth_reached = max(max_depth_reached, depth)\n",
    "        if not state or depth >= bound:\n",
    "            return current_player, None\n",
    "        \n",
    "        possible_moves = ((r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k)\n",
    "        value = current_player * math.inf, None\n",
    "\n",
    "        if current_player == 1: # my turn, minimize\n",
    "            for m in possible_moves:\n",
    "                tmp = deepcopy(state)\n",
    "                tmp.nimming(m)\n",
    "                \n",
    "                val, _ = minmax(tmp, alpha, beta, -current_player, depth + 1)\n",
    "                value = min(value, (val, m))\n",
    "                \n",
    "                if value <= alpha:\n",
    "                    break;\n",
    "\n",
    "                beta = min(beta, value)    \n",
    "            return value\n",
    "        else: # its turn, maximize\n",
    "            for m in possible_moves:\n",
    "                tmp = deepcopy(state)\n",
    "                tmp.nimming(m)\n",
    "                \n",
    "                val, _ = minmax(tmp, alpha, beta, -current_player, depth + 1)\n",
    "                value = max(value, (val, m))\n",
    "                \n",
    "                if value >= beta:\n",
    "                    break;\n",
    "\n",
    "                alpha = max(alpha, value)    \n",
    "            return value\n",
    "\n",
    "    def minmax_strategy(state: Nim):\n",
    "        _, move = minmax(state, (-math.inf, None), (math.inf, None), 1)\n",
    "        return move\n",
    "\n",
    "    return minmax_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "status: Initial board  -> <1 3 5 7>\n",
      "status: After player 0 -> <1 3 1 7>\n",
      "status: After player 1 -> <1 3 1 3>\n",
      "status: After player 0 -> <1 2 1 3>\n",
      "status: After player 1 -> <0 2 1 3>\n",
      "status: After player 0 -> <0 2 1 2>\n",
      "status: After player 1 -> <0 2 0 2>\n",
      "status: After player 0 -> <0 2 0 1>\n",
      "status: After player 1 -> <0 1 0 1>\n",
      "status: After player 0 -> <0 1 0 0>\n",
      "status: After player 1 -> <0 0 0 0>\n",
      "status: Player 1 won!\n",
      "Max depth reached by minmax: 12\n"
     ]
    }
   ],
   "source": [
    "strategy = (optimal_strategy, minmax())\n",
    "\n",
    "nim = Nim(4, None)\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim) \n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")\n",
    "\n",
    "global max_depth_reached\n",
    "logging.debug(f'Max depth reached by minmax: {max_depth_reached}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Game 0: Nim(2, 1)\n",
      "Game 1: Nim(2, None)\n",
      "Game 2: Nim(3, 1)\n",
      "Game 3: Nim(3, 2)\n",
      "Game 4: Nim(3, None)\n",
      "Game 5: Nim(4, 1)\n",
      "Game 6: Nim(4, 2)\n",
      "Game 7: Nim(4, 3)\n",
      "Game 8: Nim(4, None)\n",
      "Game 9: Nim(5, 1)\n",
      "Game 10: Nim(5, 2)\n",
      "Game 11: Nim(5, 3)\n",
      "Game 12: Nim(5, 4)\n",
      "Game 13: Nim(5, None)\n",
      "Game 14: Nim(6, 1)\n",
      "Game 15: Nim(6, 2)\n",
      "Game 16: Nim(6, 3)\n",
      "Game 17: Nim(6, 4)\n",
      "Game 18: Nim(6, 5)\n",
      "Game 19: Nim(6, None)\n",
      "Game 20: Nim(7, 1)\n",
      "Game 21: Nim(7, 2)\n",
      "Game 22: Nim(7, 3)\n",
      "Game 23: Nim(7, 4)\n",
      "Game 24: Nim(7, 5)\n",
      "Game 25: Nim(7, 6)\n",
      "Game 26: Nim(7, None)\n",
      "Game 27: Nim(8, 1)\n",
      "Game 28: Nim(8, 2)\n",
      "Game 29: Nim(8, 3)\n",
      "Game 30: Nim(8, 4)\n",
      "Game 31: Nim(8, 5)\n",
      "Game 32: Nim(8, 6)\n",
      "Game 33: Nim(8, 7)\n",
      "Game 34: Nim(8, None)\n",
      "Game 35: Nim(9, 1)\n",
      "Game 36: Nim(9, 2)\n",
      "Game 37: Nim(9, 3)\n",
      "Game 38: Nim(9, 4)\n",
      "Game 39: Nim(9, 5)\n",
      "Game 40: Nim(9, 6)\n",
      "Game 41: Nim(9, 7)\n",
      "Game 42: Nim(9, 8)\n",
      "Game 43: Nim(9, None)\n",
      "Fixed strategy win rate against Optimal strategy was 13.64 % (12.0/88)\n",
      "Fixed strategy win rate against Random strategy was 80.68 % (71.0/88)\n",
      "Evolved strategy win rate against Optimal strategy was 17.05 % (15.0/88)\n",
      "Evolved strategy win rate against Random strategy was 77.27 % (68.0/88)\n",
      "MinMax strategy win rate against Optimal strategy was 19.32 % (17.0/88)\n",
      "MinMax strategy win rate against Random strategy was 88.64 % (78.0/88)\n"
     ]
    }
   ],
   "source": [
    "games = list((a, b) for a, b in product(range(2, 10), list(range(1, 10)) + [None]) if b == None or b < a)\n",
    "opponents = [('Optimal', optimal_strategy), ('Random', random_strategy)]\n",
    "strategies = [('Fixed', fixed_strategy), ('Evolved', evolved_strategy), ('MinMax', minmax(5))]\n",
    "scores = {a[0]: [0.0 for _ in strategies] for a in opponents}\n",
    "\n",
    "for idx, pars in enumerate(games):\n",
    "    nim_size, k = pars\n",
    "    \n",
    "    logging.debug(f'Game {idx}: Nim({nim_size}, {k})')\n",
    "    \n",
    "    for idx, strategy in enumerate(strategies):\n",
    "        for opponent_name, opponent in opponents:\n",
    "            scores[opponent_name][idx] += evaluate(strategy[1], opponent, nim_size=nim_size, k=k) + 1 - evaluate(opponent, strategy[1], nim_size=nim_size, k=k) \n",
    "\n",
    "for idx, strategy in enumerate(strategies):\n",
    "    for opponent_name, _ in opponents:\n",
    "        logging.info(f'{strategy[0]} strategy win rate against {opponent_name} strategy was {round(scores[opponent_name][idx] * 100 / (2 * len(games)), 2)} % ({scores[opponent_name][idx]}/{2 * len(games)})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e660ce8e299eab6e1afd5ba1640493fbea599bc98ebfd90153bb9a99407a2701"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
