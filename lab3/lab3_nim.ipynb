{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "## Deadlines ([AoE](https://en.wikipedia.org/wiki/Anywhere_on_Earth))\n",
    "\n",
    "* Sunday, December 4th for Task3.1 and Task3.2\n",
    "* Sunday, December 11th for Task3.3 and Task3.4\n",
    "* Sunday, December 18th for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import *\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(strategyA: Callable, strategyB: Callable, num_matches = 1, nim_size = 3, k = None) -> float:\n",
    "    players = (strategyA, strategyB)\n",
    "    won = 0\n",
    "\n",
    "    for _ in range(num_matches):\n",
    "        nim = Nim(nim_size, k)\n",
    "        player = 1\n",
    "        while nim:\n",
    "            ply = players[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 1:\n",
    "            won += 1\n",
    "    return won / num_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_strategy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random non empty row and remove a random number of objects smaller than min(k, row_objects)\n",
    "\n",
    "def random_strategy(state: Nim):\n",
    "    r = random.choice([idx for idx, r in enumerate(state.rows) if r > 0])\n",
    "    num_objects = random.randint(1, min(state.rows[r], state.k) if state.k != None else state.rows[r])\n",
    "\n",
    "    return (r, num_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: Fixed-Rule Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among all possible moves, simply do this:\n",
    "# - if there is a winning move, choose it\n",
    "# - if there is not a winning move but the move puts the opponent in a winning situation, discard it\n",
    "# - otherwise choose the first move possible, even if not optimal (obliged to do a move)\n",
    "\n",
    "def fixed_strategy(state: Nim):\n",
    "    possible_moves = ((r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k)\n",
    "    move = None\n",
    "    firstMove = None\n",
    "\n",
    "    for m in possible_moves:\n",
    "        if firstMove == None:\n",
    "            firstMove = Nimply(m[0], m[1])\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        if not tmp:\n",
    "            return Nimply(m[0], m[1])\n",
    "        else:\n",
    "            active_rows = len([r for r in state.rows if r > 0])\n",
    "            eliminable_rows = len([r for r in state.rows if r > 0 and (state.k == None or r < state.k)])\n",
    "            if active_rows == eliminable_rows and eliminable_rows == 1:\n",
    "                continue\n",
    "            elif move == None:\n",
    "                move = Nimply(m[0], m[1])\n",
    "\n",
    "    return move if move != None else firstMove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Evolved Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import *\n",
    "from statistics import *\n",
    "\n",
    "GENOME_LENGTH = 11 # NB: GENOME_LENGTH must be of the form 4*n + 3 with n > 0, if n > 1 it may converge to the xor solution\n",
    "GAMES = 5\n",
    "GAME_PARS = list((nim_size, k) for nim_size, k in ((random.randint(3, 10), random.choice([None, random.randint(1, 10)])) for _ in range(GAMES)))\n",
    "\n",
    "def decode_genome(genome):\n",
    "    assert (GENOME_LENGTH - 3) % 4 == 0 and GENOME_LENGTH > 0, 'GENOME_LENGTH must be of the form 4*n + 3 with n > 0'\n",
    "    out = \"\"\n",
    "\n",
    "    for op_start in range(0, GENOME_LENGTH, 4):\n",
    "        tmpA = 'a' if genome[op_start] < 0.5 else '!a'\n",
    "        tmpB = 'b' if genome[op_start + 2] < 0.5 else '!b'\n",
    "        internal_op = '&' if genome[op_start + 1] < 0.5 else '|'\n",
    "        op = ('&' if genome[op_start + 3] < 0.5 else '|') if op_start + 3 < GENOME_LENGTH else ''\n",
    "        out += f'({tmpA} {internal_op} {tmpB}) {op} '\n",
    "\n",
    "    return out[:-2]\n",
    "\n",
    "\n",
    "def evolvable_strategy(genome):\n",
    "    assert (GENOME_LENGTH - 3) % 4 == 0 and GENOME_LENGTH > 0, 'GENOME_LENGTH must be of the form 4*n + 3 with n > 0'\n",
    "\n",
    "    def genetic_op(a, b):\n",
    "        result = 0\n",
    "        op = lambda _, b: b\n",
    "\n",
    "        for op_start in range(0, GENOME_LENGTH, 4):\n",
    "            tmpA = a if genome[op_start] < 0.5 else ~a\n",
    "            tmpB = b if genome[op_start + 2] < 0.5 else ~b\n",
    "            internal_op = and_ if genome[op_start + 1] < 0.5 else or_\n",
    "            result = op(result, internal_op(tmpA, tmpB))\n",
    "            op = (and_ if genome[op_start + 3] < 0.5 else or_) if op_start + 3 < GENOME_LENGTH else None\n",
    "\n",
    "        return result\n",
    "\n",
    "    def strategy(state: Nim):\n",
    "            possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k]\n",
    "            best = None\n",
    "\n",
    "            for m in possible_moves:\n",
    "                tmp = deepcopy(state)\n",
    "                tmp.nimming(m)\n",
    "                \n",
    "                val = reduce(genetic_op, tmp.rows)\n",
    "\n",
    "                if best == None or best[1] > val:\n",
    "                    best = (m, val)\n",
    "                             \n",
    "            return best[0]\n",
    "    \n",
    "    return strategy\n",
    "\n",
    "def mutation(genome):\n",
    "    point = random.randint(0, len(genome) - 1)\n",
    "    return genome[:point] + [1 - genome[point]] + genome[point + 1:]\n",
    "\n",
    "def crossover(genomeA, genomeB):\n",
    "    p = random.random()\n",
    "    return [x if p < 0.5 else y for x, y in zip(genomeA, genomeB)]\n",
    "\n",
    "def tournament(population, tournament_size):\n",
    "    return max(random.choices(population, k=tournament_size), key=lambda i: i.fitness)\n",
    "\n",
    "def fitness(genome):\n",
    "    win_optimal = 0.0\n",
    "    win_random = 0.0\n",
    "\n",
    "    for nim_size, k in GAME_PARS:\n",
    "        home = evaluate(evolvable_strategy(genome), random_strategy, nim_size=nim_size, k=k) \n",
    "        away = 1 - evaluate(random_strategy, evolvable_strategy(genome), nim_size=nim_size, k=k)\n",
    "        win_random += home + away\n",
    "        home = evaluate(evolvable_strategy(genome), optimal_strategy, nim_size=nim_size, k=k) \n",
    "        away = 1 - evaluate(optimal_strategy, evolvable_strategy(genome), nim_size=nim_size, k=k)\n",
    "        win_optimal += home + away\n",
    "\n",
    "    return (win_optimal/(2*GAMES), win_random/(2*GAMES))\n",
    "        \n",
    "def genetic_algorithm():\n",
    "    Individual = namedtuple('Individual', ('genome', 'fitness'))\n",
    "\n",
    "    NUM_GENS = 100    \n",
    "    POPULATION_SIZE = 10\n",
    "    OFFSPRING_SIZE = 20\n",
    "    TOURNAMENT_SIZE = 2\n",
    "    USELESS_GENS = 0\n",
    "    STEADY_STATE_LIMIT = 10\n",
    "\n",
    "    population = [Individual(i, fitness(i)) for i in ([round(random.random(), 2) for _ in range(GENOME_LENGTH)] for _ in range(POPULATION_SIZE))]\n",
    "    best = None\n",
    "    \n",
    "    for g in range(NUM_GENS):\n",
    "        offspring = list()\n",
    "        for i in range(OFFSPRING_SIZE):\n",
    "            if random.random() < 0.3:\n",
    "                p = tournament(population, tournament_size=TOURNAMENT_SIZE)\n",
    "                o = mutation(p.genome)\n",
    "            else:\n",
    "                p1 = tournament(population, tournament_size=TOURNAMENT_SIZE)\n",
    "                p2 = tournament(population, tournament_size=TOURNAMENT_SIZE)\n",
    "                o = crossover(p1.genome, p2.genome)\n",
    "            f = fitness(o)\n",
    "            offspring.append(Individual(o, f))\n",
    "        population += offspring\n",
    "        population = sorted(population, key=lambda i: i.fitness, reverse=True)[:POPULATION_SIZE]\n",
    "        newBest = max(population, key=lambda i: i.fitness)\n",
    "\n",
    "        if best != None and newBest <= best:\n",
    "            logging.info(f'Gen {g+1} skipped because useless')\n",
    "            USELESS_GENS += 1\n",
    "        else:\n",
    "            logging.info(f'Gen {g+1}, found new best individual: {decode_genome(newBest.genome)} with fitness = {newBest.fitness}')\n",
    "            best = newBest\n",
    "            USELESS_GENS = 0\n",
    "        \n",
    "        if USELESS_GENS == STEADY_STATE_LIMIT:\n",
    "            logging.info(f'Gen {g+1}, no improvements after {USELESS_GENS} gens, terminating...')\n",
    "            break\n",
    "\n",
    "    logging.info(f'Best individual: {decode_genome(best.genome)} with genome {best.genome} fitness = {best.fitness}')\n",
    "\n",
    "    return evolvable_strategy(best.genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gen 1, found new best individual: (a & b) & (!a | b) | (!a & !b) with fitness = (0.4, 0.9)\n",
      "INFO:root:Gen 2, found new best individual: (a & b) & (!a | b) | (!a & !b) with fitness = (0.4, 1.0)\n",
      "INFO:root:Gen 3 skipped because useless\n",
      "INFO:root:Gen 4 skipped because useless\n",
      "INFO:root:Gen 5 skipped because useless\n",
      "INFO:root:Gen 6 skipped because useless\n",
      "INFO:root:Gen 7 skipped because useless\n",
      "INFO:root:Gen 8 skipped because useless\n",
      "INFO:root:Gen 9 skipped because useless\n",
      "INFO:root:Gen 10 skipped because useless\n",
      "INFO:root:Gen 11 skipped because useless\n",
      "INFO:root:Gen 12 skipped because useless\n",
      "INFO:root:Gen 12, no improvements after 10 gens, terminating...\n",
      "INFO:root:Best individual: (a & b) & (!a | b) | (!a & !b) with genome [0.49, 0.09, 0.38, 0.10999999999999999, 0.88, 0.64, 0.47, 0.79, 0.63, 0.06, 0.68] fitness = (0.4, 1.0)\n"
     ]
    }
   ],
   "source": [
    "evolved_strategy = genetic_algorithm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:status: Initial board  -> <1 3 5>\n",
      "DEBUG:root:status: After player 0 -> <1 3 2>\n",
      "DEBUG:root:status: After player 1 -> <0 3 2>\n",
      "DEBUG:root:status: After player 0 -> <0 2 2>\n",
      "DEBUG:root:status: After player 1 -> <0 2 1>\n",
      "DEBUG:root:status: After player 0 -> <0 1 1>\n",
      "DEBUG:root:status: After player 1 -> <0 0 1>\n",
      "DEBUG:root:status: After player 0 -> <0 0 0>\n",
      "INFO:root:status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "xor_strategy = evolvable_strategy([0, 0, 1, 1, 1, 0, 0])\n",
    "strategy = (evolved_strategy, optimal_strategy)\n",
    "\n",
    "nim = Nim(3, None)\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim) \n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fixed strategy win rate against random strategy was 82.5 % (165.0/200)\n",
      "INFO:root:Evolved strategy win rate against random strategy was 65.0 % (130.0/200)\n",
      "INFO:root:Fixed strategy win rate against optimal strategy was 4.5 % (9.0/200)\n",
      "INFO:root:Evolved strategy win rate against optimal strategy was 23.0 % (46.0/200)\n"
     ]
    }
   ],
   "source": [
    "games = 100\n",
    "wins_fixed_strategy = 0.0\n",
    "wins_evolved_strategy = 0.0\n",
    "wins_fixed_strategy_rand = 0.0\n",
    "wins_evolved_strategy_rand = 0.0\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "for idx, pars in enumerate(((nim_size, k) for nim_size, k in ((random.randint(3, 10), random.choice([None, random.randint(1, 10)])) for _ in range(games)))):\n",
    "    nim_size, k = pars\n",
    "    \n",
    "    logging.debug(f'Game {idx}: Nim({nim_size}, {k})')\n",
    "    \n",
    "    home = evaluate(fixed_strategy, optimal_strategy, nim_size=nim_size, k=k) \n",
    "    away = 1 - evaluate(optimal_strategy, fixed_strategy, nim_size=nim_size, k=k)\n",
    "    wins_fixed_strategy += home + away\n",
    "\n",
    "    home = evaluate(evolved_strategy, optimal_strategy, nim_size=nim_size, k=k) \n",
    "    away = 1 - evaluate(optimal_strategy, evolved_strategy, nim_size=nim_size, k=k)\n",
    "    wins_evolved_strategy += home + away\n",
    "\n",
    "    home = evaluate(fixed_strategy, random_strategy, nim_size=nim_size, k=k) \n",
    "    away = 1 - evaluate(random_strategy, fixed_strategy, nim_size=nim_size, k=k)\n",
    "    wins_fixed_strategy_rand += home + away\n",
    "\n",
    "    home = evaluate(evolved_strategy, random_strategy, nim_size=nim_size, k=k) \n",
    "    away = 1 - evaluate(random_strategy, evolved_strategy, nim_size=nim_size, k=k)\n",
    "    wins_evolved_strategy_rand += home + away\n",
    "\n",
    "logging.info(f'Fixed strategy win rate against random strategy was {wins_fixed_strategy_rand * 100 / (2 * games)} % ({wins_fixed_strategy_rand}/{2 * games})')\n",
    "logging.info(f'Evolved strategy win rate against random strategy was {wins_evolved_strategy_rand * 100 / (2 * games)} % ({wins_evolved_strategy_rand}/{2 * games})')\n",
    "logging.info(f'Fixed strategy win rate against optimal strategy was {wins_fixed_strategy * 100 / (2 * games)} % ({wins_fixed_strategy}/{2 * games})')\n",
    "logging.info(f'Evolved strategy win rate against optimal strategy was {wins_evolved_strategy * 100 / (2 * games)} % ({wins_evolved_strategy}/{2 * games})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e660ce8e299eab6e1afd5ba1640493fbea599bc98ebfd90153bb9a99407a2701"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
